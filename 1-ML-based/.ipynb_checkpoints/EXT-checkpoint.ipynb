{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5879c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve, auc, mean_squared_error, \\\n",
    "    r2_score, mean_absolute_error,cohen_kappa_score,accuracy_score,f1_score,matthews_corrcoef,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "start = time.time()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def standardize(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "# the metrics for classification\n",
    "def statistical(y_true, y_pred, y_pro):\n",
    "    c_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = list(c_mat.flatten())\n",
    "    se = tp / (tp + fn)\n",
    "    sp = tn / (tn + fp)\n",
    "    auc_prc = auc(precision_recall_curve(y_true, y_pro, pos_label=1)[1],\n",
    "                  precision_recall_curve(y_true, y_pro, pos_label=1)[0])\n",
    "    acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "#     acc_skl = accuracy_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pro)\n",
    "    recall = se\n",
    "#     recall_skl = recall_score(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "#     precision_skl = precision_score(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     f1_skl = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    mcc = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) + 1e-8)\n",
    "#     mcc_skl = matthews_corrcoef(y_true,y_pred)\n",
    "    return tn,fp,fn,tp,se,sp,auc_prc,acc,auc_roc,recall,precision,f1,kappa,mcc\n",
    "\n",
    "def all_one_zeros(data):\n",
    "    if (len(np.unique(data)) == 2):\n",
    "        flag = False\n",
    "    else:\n",
    "        flag = True\n",
    "    return flag\n",
    "\n",
    "\n",
    "feature_selection = False\n",
    "tasks_dic = {'AR-Alva-6108-slim-group.csv': ['activity']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8d2bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'actual_estimator__n_estimators': IntUniformDistribution(high=300, low=10, step=1),\n",
    "#  'actual_estimator__max_depth': IntUniformDistribution(high=11, low=1, step=1),\n",
    "#  'actual_estimator__min_samples_split': IntUniformDistribution(high=10, low=2, step=1),\n",
    "#  'actual_estimator__min_samples_leaf': IntUniformDistribution(high=5, low=1, step=1),\n",
    "#  'actual_estimator__max_features': UniformDistribution(high=1.0, low=0.4),\n",
    "#  'actual_estimator__min_impurity_decrease': LogUniformDistribution(high=0.5, low=1e-09),\n",
    "#  'actual_estimator__criterion': CategoricalDistribution(choices=('gini', 'entropy')),\n",
    "#  'actual_estimator__bootstrap': CategoricalDistribution(choices=(True, False)),\n",
    "#  'actual_estimator__class_weight': CategoricalDistribution(choices=('balanced', 'balanced_subsample', {}))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6daf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'AR-Alva-6108-slim-group.csv'\n",
    "task_type = 'cla'  # 'reg' or 'cla'\n",
    "dataset_label = file_name.split('/')[-1].split('_')[0]\n",
    "tasks = tasks_dic[dataset_label]\n",
    "OPT_ITERS = 50\n",
    "repetitions = 10\n",
    "num_pools = 10\n",
    "unbalance = True\n",
    "patience = 100\n",
    "ecfp = False\n",
    "# preset the hyper_parameters_space \n",
    "space_ = {\n",
    "          'n_estimators': hp.choice('n_estimators', range(10,300,1)),\n",
    "          'max_depth': hp.choice('max_depth', range(1,11,1)),\n",
    "          'min_samples_split': hp.choice('min_samples_split', range(2,10,1)),\n",
    "          'min_samples_leaf': hp.choice('min_samples_leaf', range(1,5,1)),\n",
    "          'max_features': hp.uniform('max_features', 0.4, 1.0),\n",
    "          'min_impurity_decrease': hp.uniform('min_impurity_decrease', 0.005,5),\n",
    "          'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "          'bootstrap': hp.choice('bootstrap', [True,False]),\n",
    "#           'class_weight': hp.choice('class_weight', ['balanced', 'balanced_subsample',{}])\n",
    "          }\n",
    "\n",
    "n_estimators_ls = range(10,300,1)\n",
    "max_depth_ls =  range(1,11,1)\n",
    "min_samples_split_ls = range(2,10,1)\n",
    "min_samples_leaf_ls = range(1,5,1)\n",
    "criterion_ls = ['gini', 'entropy']\n",
    "bootstrap_ls = [True,False]\n",
    "# class_weight_ls = ['balanced', 'balanced_subsample',{}]\n",
    "\n",
    "dataset = pd.read_csv(file_name)\n",
    "pd_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5508043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the num of retained features for the AR-Alva-6108-slim-group.csv activity is: 1492\n",
      "the best hyper-parameters for AR-Alva-6108-slim-group.csv activity are:   {'bootstrap': 0, 'criterion': 1, 'max_depth': 3, 'max_features': 0.8953054864887171, 'min_impurity_decrease': 0.015181309329324932, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 181}\n",
      "train 0.8973130720357515 0.7578880002271698\n",
      "valid 0.883542001070091 0.7080169418039977\n",
      "test 0.9008676641388262 0.745839993220364\n"
     ]
    }
   ],
   "source": [
    "def hyper_runing(subtask):\n",
    "    cols = [subtask]\n",
    "    cols.extend(dataset.columns[(len(tasks) + 1):])\n",
    "    sub_dataset = dataset[cols]\n",
    "\n",
    "    # detect the na in the subtask (y cloumn)\n",
    "    rm_index = sub_dataset[subtask][sub_dataset[subtask].isnull()].index\n",
    "    sub_dataset.drop(index=rm_index, inplace=True)\n",
    "\n",
    "    # remove the features with na\n",
    "    sub_dataset = sub_dataset.dropna(axis=1)\n",
    "    # *******************\n",
    "    # demension reduction\n",
    "    # *******************\n",
    "    # Removing features with low variance\n",
    "    # threshold = 0.05\n",
    "    data_fea_var = sub_dataset.iloc[:, 2:].var()\n",
    "    del_fea1 = list(data_fea_var[data_fea_var <= 0.05].index)\n",
    "    sub_dataset.drop(columns=del_fea1, inplace=True)\n",
    "\n",
    "    # pair correlations\n",
    "    # threshold = 0.95\n",
    "    data_fea_corr = sub_dataset.iloc[:, 2:].corr()\n",
    "    del_fea2_col = []\n",
    "    del_fea2_ind = []\n",
    "    length = data_fea_corr.shape[1]\n",
    "    for i in range(length):\n",
    "        for j in range(i + 1, length):\n",
    "            if abs(data_fea_corr.iloc[i, j]) >= 0.95:\n",
    "                del_fea2_col.append(data_fea_corr.columns[i])\n",
    "                del_fea2_ind.append(data_fea_corr.index[j])\n",
    "    sub_dataset.drop(columns=del_fea2_ind, inplace=True)\n",
    "\n",
    "    # standardize the features\n",
    "    cols_ = list(sub_dataset.columns)[2:]\n",
    "    if not ecfp :\n",
    "        sub_dataset[cols_] = sub_dataset[cols_].apply(standardize, axis=0)\n",
    "\n",
    "    # get the attentivefp data splits\n",
    "    data_tr = sub_dataset[sub_dataset['group'] == 'train']\n",
    "    data_va = sub_dataset[sub_dataset['group'] == 'valid']\n",
    "    data_te = sub_dataset[sub_dataset['group'] == 'test']\n",
    "\n",
    "    # prepare data for training\n",
    "    # training set\n",
    "    data_tr_y = data_tr[subtask].values.reshape(-1, 1)\n",
    "    data_tr_x = np.array(data_tr.iloc[:, 2:].values)\n",
    "\n",
    "    # validation set\n",
    "    data_va_y = data_va[subtask].values.reshape(-1, 1)\n",
    "    data_va_x = np.array(data_va.iloc[:, 2:].values)\n",
    "\n",
    "    # test set\n",
    "    data_te_y = data_te[subtask].values.reshape(-1, 1)\n",
    "    data_te_x = np.array(data_te.iloc[:, 2:].values)\n",
    "\n",
    "    if feature_selection:\n",
    "        # univariate feature selection\n",
    "        trans1 = SelectPercentile(f_classif, percentile=80)\n",
    "        trans1.fit(data_tr_x, data_tr_y)\n",
    "        data_tr_x = trans1.transform(data_tr_x)\n",
    "        data_va_x = trans1.transform(data_va_x)\n",
    "        data_te_x = trans1.transform(data_te_x)\n",
    "\n",
    "        # select from model\n",
    "        clf = XGBClassifier(random_state=1)\n",
    "        clf = clf.fit(data_tr_x, data_tr_y)\n",
    "        trans2 = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "        data_tr_x = trans2.transform(data_tr_x)\n",
    "        data_va_x = trans2.transform(data_va_x)\n",
    "        data_te_x = trans2.transform(data_te_x)\n",
    "\n",
    "    num_fea = data_tr_x.shape[1]\n",
    "    print('the num of retained features for the ' + dataset_label + ' ' + subtask + ' is:', num_fea)\n",
    "\n",
    "    def hyper_opt(args):\n",
    "        model = ExtraTreesClassifier(**args) if task_type == 'cla' else ExtraTreesRegressor(**args)\n",
    "\n",
    "        model.fit(data_tr_x, data_tr_y)\n",
    "        val_preds = model.predict_proba(data_va_x) if task_type == 'cla' else \\\n",
    "            model.predict(data_va_x)\n",
    "        loss = 1 - roc_auc_score(data_va_y, val_preds[:, 1]) if task_type == 'cla' else np.sqrt(\n",
    "            mean_squared_error(data_va_y, val_preds))\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    # start hyper-parameters optimization\n",
    "    trials = Trials()\n",
    "    best_results = fmin(hyper_opt, space_, algo=tpe.suggest, max_evals=OPT_ITERS, trials=trials, show_progressbar=False)\n",
    "    print('the best hyper-parameters for ' + dataset_label + ' ' + subtask + ' are:  ', best_results)\n",
    "    \n",
    "    best_model = ExtraTreesClassifier(  \n",
    "                                        n_estimators= n_estimators_ls[best_results['n_estimators']],\n",
    "                                        max_depth = max_depth_ls[best_results['max_depth']],\n",
    "                                        min_samples_split=min_samples_split_ls[best_results['min_samples_split']],\n",
    "                                        min_samples_leaf=min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                                        max_features=best_results['max_features'],\n",
    "                                        min_impurity_decrease=best_results['min_impurity_decrease'],\n",
    "                                        criterion=criterion_ls[best_results['criterion']],\n",
    "                                        bootstrap=bootstrap_ls[best_results['bootstrap']],\n",
    "#                                         class_weight=class_weight_ls[best_results['class_weight']]\n",
    "                                      ) \\\n",
    "        if task_type == 'cla' else ExtraTreesRegressor(\n",
    "                                        n_estimators= n_estimators_ls[best_results['n_estimators']],\n",
    "                                        max_depth = max_depth_ls[best_results['max_depth']],\n",
    "                                        min_samples_split=min_samples_split_ls[best_results['min_samples_split']],\n",
    "                                        min_samples_leaf=min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                                        max_features=best_results['max_features'],\n",
    "                                        min_impurity_decrease=best_results['min_impurity_decrease'],\n",
    "                                        criterion=criterion_ls[best_results['criterion']],\n",
    "                                        bootstrap=bootstrap_ls[best_results['bootstrap']],\n",
    "#                                         class_weight=class_weight_ls[best_results['class_weight']]\n",
    "                                      )  \n",
    "    \n",
    "    best_model.fit(data_tr_x, data_tr_y)\n",
    "    \n",
    "    num_of_compounds = len(sub_dataset)\n",
    "\n",
    "    if task_type == 'cla':\n",
    "        # training set\n",
    "        tr_pred = best_model.predict_proba(data_tr_x)\n",
    "        tr_results = [dataset_label, subtask, 'tr', num_fea, num_of_compounds, data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0] / data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      best_results['max_features'],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      criterion_ls[best_results['criterion']],\n",
    "                      bootstrap_ls[best_results['bootstrap']],\n",
    "#                       class_weight_ls[best_results['class_weight']]\n",
    "                     ]\n",
    "        tr_results.extend(statistical(data_tr_y, np.argmax(tr_pred, axis=1), tr_pred[:, 1]))\n",
    "        # validation set\n",
    "        va_pred = best_model.predict_proba(data_va_x)\n",
    "                      \n",
    "        va_results = [dataset_label, subtask, 'va', num_fea, num_of_compounds, data_va_y[data_va_y == 1].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0] / data_va_y[data_va_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      best_results['max_features'],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      criterion_ls[best_results['criterion']],\n",
    "                      bootstrap_ls[best_results['bootstrap']],\n",
    "#                       class_weight_ls[best_results['class_weight']]\n",
    "                     ]\n",
    "        va_results.extend(statistical(data_va_y, np.argmax(va_pred, axis=1), va_pred[:, 1]))\n",
    "\n",
    "        # test set\n",
    "        te_pred = best_model.predict_proba(data_te_x)\n",
    "        te_results = [dataset_label, subtask, 'te', num_fea, num_of_compounds, data_te_y[data_te_y == 1].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0] / data_te_y[data_te_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      best_results['max_features'],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      criterion_ls[best_results['criterion']],\n",
    "                      bootstrap_ls[best_results['bootstrap']],\n",
    "#                       class_weight_ls[best_results['class_weight']]\n",
    "                     ]\n",
    "        te_results.extend(statistical(data_te_y, np.argmax(te_pred, axis=1), te_pred[:, 1]))\n",
    "    else:\n",
    "        # training set\n",
    "        tr_pred = best_model.predict(data_tr_x)\n",
    "        tr_results = [dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      best_results['max_features'],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      criterion_ls[best_results['criterion']],\n",
    "                      bootstrap_ls[best_results['bootstrap']],\n",
    "#                       class_weight_ls[best_results['class_weight']],\n",
    "                      np.sqrt(mean_squared_error(data_tr_y, tr_pred)), r2_score(data_tr_y, tr_pred),\n",
    "                      mean_absolute_error(data_tr_y, tr_pred)]\n",
    "\n",
    "        # validation set\n",
    "        va_pred = best_model.predict(data_va_x)\n",
    "        va_results = [dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      best_results['max_features'],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      criterion_ls[best_results['criterion']],\n",
    "                      bootstrap_ls[best_results['bootstrap']],\n",
    "#                       class_weight_ls[best_results['class_weight']],\n",
    "                      np.sqrt(mean_squared_error(data_va_y, va_pred)), r2_score(data_va_y, va_pred),\n",
    "                      mean_absolute_error(data_va_y, va_pred)]\n",
    "\n",
    "        # test set\n",
    "        te_pred = best_model.predict(data_te_x)\n",
    "        te_results = [dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      best_results['max_features'],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      criterion_ls[best_results['criterion']],\n",
    "                      bootstrap_ls[best_results['bootstrap']],\n",
    "#                       class_weight_ls[best_results['class_weight']],\n",
    "                      np.sqrt(mean_squared_error(data_te_y, te_pred)), r2_score(data_te_y, te_pred),\n",
    "                      mean_absolute_error(data_te_y, te_pred)]\n",
    "    return tr_results, va_results, te_results\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(num_pools)\n",
    "res = pool.starmap(hyper_runing, zip(tasks))\n",
    "pool.close()\n",
    "pool.join()\n",
    "for item in res:\n",
    "    for i in range(3):\n",
    "        pd_res.append(item[i])\n",
    "if task_type == 'cla':       \n",
    "                                            \n",
    "    best_hyper = pd.DataFrame(pd_res, columns=['dataset', 'subtask', 'set',\n",
    "                                               'num_of_retained_feature',\n",
    "                                               'num_of_compounds', 'postives',\n",
    "                                               'negtives', 'negtives/postives',\n",
    "                                               'n_estimators',\n",
    "                                               'max_depth',\n",
    "                                               'min_samples_split','min_samples_leaf','max_features','min_impurity_decrease',\n",
    "                                               'criterion','bootstrap',\n",
    "#                                                'class_weight',\n",
    "                                               'tn', 'fp', 'fn', 'tp', 'se', 'sp',\n",
    "                                               'auc_prc', 'acc', 'auc_roc','recall','precision','f1','kappa','mcc'])\n",
    "else:\n",
    "    best_hyper = pd.DataFrame(pd_res, columns=['dataset', 'subtask', 'set',\n",
    "                                               'n_estimators',\n",
    "                                               'max_depth',\n",
    "                                               'min_samples_split','min_samples_leaf','max_features','min_impurity_decrease',\n",
    "                                               'criterion','bootstrap',\n",
    "#                                                'class_weight',\n",
    "                                               'rmse', 'r2', 'mae'])\n",
    "best_hyper.to_csv('./model/' + dataset_label + '_EXT_hyperopt_info.csv', index=0)\n",
    "\n",
    "if task_type == 'cla':\n",
    "    print('train', best_hyper[best_hyper['set'] == 'tr']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'tr']['auc_prc'].mean())\n",
    "    print('valid', best_hyper[best_hyper['set'] == 'va']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'va']['auc_prc'].mean())\n",
    "    print('test', best_hyper[best_hyper['set'] == 'te']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'te']['auc_prc'].mean())\n",
    "else:\n",
    "    print('train', best_hyper[best_hyper['set'] == 'tr']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'tr']['r2'].mean(), best_hyper[best_hyper['set'] == 'tr']['mae'].mean())\n",
    "    print('valid', best_hyper[best_hyper['set'] == 'va']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'va']['r2'].mean(), best_hyper[best_hyper['set'] == 'va']['mae'].mean())\n",
    "    print('test', best_hyper[best_hyper['set'] == 'te']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'te']['r2'].mean(), best_hyper[best_hyper['set'] == 'te']['mae'].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67e5b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 repetitions based on thr best hypers\n",
    "dataset.drop(columns=['group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49892864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed used in repetition 1 is 1\n",
      "random seed used in repetition 3 is 3\n",
      "random seed used in repetition 7 is 7\n",
      "random seed used in repetition 6 is 6\n",
      "random seed used in repetition 2 is 2\n",
      "random seed used in repetition 10 is 10\n",
      "random seed used in repetition 8 is 8\n",
      "random seed used in repetition 9 is 9\n",
      "random seed used in repetition 5 is 5\n",
      "random seed used in repetition 4 is 4\n",
      "AR-Alva-6108-slim-group.csv_EXT: the mean auc_roc for the training set is 0.898 with std 0.002\n",
      "AR-Alva-6108-slim-group.csv_EXT: the mean auc_roc for the validation set is 0.897 with std 0.012\n",
      "AR-Alva-6108-slim-group.csv_EXT: the mean auc_roc for the test set is 0.899 with std 0.013\n"
     ]
    }
   ],
   "source": [
    "pd_res = []\n",
    "def best_model_runing(split):\n",
    "    seed = split\n",
    "    if task_type == 'cla':\n",
    "        while True:\n",
    "            training_data, data_te = train_test_split(sub_dataset, test_size=0.1, random_state=seed)\n",
    "            # the training set was further splited into the training set and validation set\n",
    "            data_tr, data_va = train_test_split(training_data, test_size=0.1, random_state=seed)\n",
    "            if (all_one_zeros(data_tr[subtask]) or all_one_zeros(data_va[subtask]) or all_one_zeros(data_te[subtask])):\n",
    "                print(\n",
    "                    '\\ninvalid random seed {} due to one class presented in the {} splitted sets...'.format(seed,\n",
    "                                                                                                            subtask))\n",
    "                print('Changing to another random seed...\\n')\n",
    "                seed = np.random.randint(10, 999999)\n",
    "            else:\n",
    "                print('random seed used in repetition {} is {}'.format(split, seed))\n",
    "                break\n",
    "    else:\n",
    "        training_data, data_te = train_test_split(sub_dataset, test_size=0.1, random_state=seed)\n",
    "        # the training set was further splited into the training set and validation set\n",
    "        data_tr, data_va = train_test_split(training_data, test_size=0.1, random_state=seed)\n",
    "\n",
    "    # prepare data for training\n",
    "    # training set\n",
    "    data_tr_y = data_tr[subtask].values.reshape(-1, 1)\n",
    "    data_tr_x = np.array(data_tr.iloc[:, 1:].values)\n",
    "\n",
    "    # validation set\n",
    "    data_va_y = data_va[subtask].values.reshape(-1, 1)\n",
    "    data_va_x = np.array(data_va.iloc[:, 1:].values)\n",
    "\n",
    "    # test set\n",
    "    data_te_y = data_te[subtask].values.reshape(-1, 1)\n",
    "    data_te_x = np.array(data_te.iloc[:, 1:].values)\n",
    "\n",
    "    if feature_selection:\n",
    "        # univariate feature selection\n",
    "        trans1 = SelectPercentile(f_classif, percentile=80)\n",
    "        trans1.fit(data_tr_x, data_tr_y)\n",
    "        data_tr_x = trans1.transform(data_tr_x)\n",
    "        data_va_x = trans1.transform(data_va_x)\n",
    "        data_te_x = trans1.transform(data_te_x)\n",
    "\n",
    "        # select from model\n",
    "        clf = XGBClassifier(random_state=1)\n",
    "        clf = clf.fit(data_tr_x, data_tr_y)\n",
    "        trans2 = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "        data_tr_x = trans2.transform(data_tr_x)\n",
    "        data_va_x = trans2.transform(data_va_x)\n",
    "        data_te_x = trans2.transform(data_te_x)     \n",
    "        \n",
    "    num_fea = data_tr_x.shape[1]\n",
    "    pos_weight = (len(sub_dataset) - sum(sub_dataset[subtask])) / sum(sub_dataset[subtask])\n",
    "    model = ExtraTreesClassifier(\n",
    "                          n_estimators=best_hyper[best_hyper.subtask == subtask].iloc[0,]['n_estimators'],\n",
    "                          max_depth=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_depth'],\n",
    "                          min_samples_split=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_split'],\n",
    "                          min_samples_leaf=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_leaf'],\n",
    "                          max_features=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_features'],\n",
    "                          min_impurity_decrease=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_impurity_decrease'],\n",
    "                          criterion=best_hyper[best_hyper.subtask == subtask].iloc[0,]['criterion'],\n",
    "                          bootstrap=best_hyper[best_hyper.subtask == subtask].iloc[0,]['bootstrap'],\n",
    "#                           class_weight=best_hyper[best_hyper.subtask == subtask].iloc[0,]['class_weight']\n",
    "                          ) \\\n",
    "        if task_type == 'cla' else ExtraTreesRegressor(\n",
    "                          n_estimators=best_hyper[best_hyper.subtask == subtask].iloc[0,]['n_estimators'],\n",
    "                          max_depth=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_depth'],\n",
    "                          min_samples_split=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_split'],\n",
    "                          min_samples_leaf=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_leaf'],\n",
    "                          max_features=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_features'],\n",
    "                          min_impurity_decrease=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_impurity_decrease'],\n",
    "                          criterion=best_hyper[best_hyper.subtask == subtask].iloc[0,]['criterion'],\n",
    "                          bootstrap=best_hyper[best_hyper.subtask == subtask].iloc[0,]['bootstrap'],\n",
    "#                           class_weight=best_hyper[best_hyper.subtask == subtask].iloc[0,]['class_weight']\n",
    "                          )\n",
    "\n",
    "    model.fit(data_tr_x, data_tr_y)\n",
    "    num_of_compounds = sub_dataset.shape[0]\n",
    "    import pickle\n",
    "    pickle.dump(model, open(\"./model/ext_\"+str(split)+\".pkl\", \"wb\"))\n",
    "    if task_type == 'cla':\n",
    "        # training set\n",
    "        tr_pred = model.predict_proba(data_tr_x)\n",
    "        tr_results = [split, dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0] / data_tr_y[data_tr_y == 1].shape[0]]\n",
    "        tr_results.extend(statistical(data_tr_y, np.argmax(tr_pred, axis=1), tr_pred[:, 1]))\n",
    "\n",
    "        # validation set\n",
    "        va_pred = model.predict_proba(data_va_x)\n",
    "        va_results = [split, dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      data_va_y[data_va_y == 1].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0] / data_va_y[data_va_y == 1].shape[0]]\n",
    "        va_results.extend(statistical(data_va_y, np.argmax(va_pred, axis=1), va_pred[:, 1]))\n",
    "\n",
    "        # test set\n",
    "        te_pred = model.predict_proba(data_te_x)\n",
    "        te_results = [split, dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      data_te_y[data_te_y == 1].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0] / data_te_y[data_te_y == 1].shape[0]]\n",
    "        te_results.extend(statistical(data_te_y, np.argmax(te_pred, axis=1), te_pred[:, 1]))\n",
    "    else:\n",
    "        # training set\n",
    "        tr_pred = model.predict(data_tr_x)\n",
    "        tr_results = [split, dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_tr_y, tr_pred)), r2_score(data_tr_y, tr_pred),\n",
    "                      mean_absolute_error(data_tr_y, tr_pred)]\n",
    "\n",
    "        # validation set\n",
    "        va_pred = model.predict(data_va_x)\n",
    "        va_results = [split, dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_va_y, va_pred)), r2_score(data_va_y, va_pred),\n",
    "                      mean_absolute_error(data_va_y, va_pred)]\n",
    "\n",
    "        # test set\n",
    "        te_pred = model.predict(data_te_x)\n",
    "        te_results = [split, dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_te_y, te_pred)), r2_score(data_te_y, te_pred),\n",
    "                      mean_absolute_error(data_te_y, te_pred)]\n",
    "    return tr_results, va_results, te_results\n",
    "\n",
    "\n",
    "for subtask in tasks:\n",
    "    cols = [subtask]\n",
    "    cols.extend(dataset.columns[(len(tasks) + 1):])\n",
    "    sub_dataset = dataset[cols]\n",
    "\n",
    "    # detect the NA in the subtask (y cloumn)\n",
    "    rm_index = sub_dataset[subtask][sub_dataset[subtask].isnull()].index\n",
    "    sub_dataset.drop(index=rm_index, inplace=True)\n",
    "\n",
    "    # remove the features with na\n",
    "    sub_dataset = sub_dataset.dropna(axis=1)\n",
    "    # *******************\n",
    "    # demension reduction\n",
    "    # *******************\n",
    "    # Removing features with low variance\n",
    "    # threshold = 0.05\n",
    "    data_fea_var = sub_dataset.iloc[:, 1:].var()\n",
    "    del_fea1 = list(data_fea_var[data_fea_var <= 0.05].index)\n",
    "    sub_dataset.drop(columns=del_fea1, inplace=True)\n",
    "\n",
    "    # pair correlations\n",
    "    # threshold = 0.95\n",
    "    data_fea_corr = sub_dataset.iloc[:, 1:].corr()\n",
    "    del_fea2_col = []\n",
    "    del_fea2_ind = []\n",
    "    length = data_fea_corr.shape[1]\n",
    "    for i in range(length):\n",
    "        for j in range(i + 1, length):\n",
    "            if abs(data_fea_corr.iloc[i, j]) >= 0.95:\n",
    "                del_fea2_col.append(data_fea_corr.columns[i])\n",
    "                del_fea2_ind.append(data_fea_corr.index[j])\n",
    "    sub_dataset.drop(columns=del_fea2_ind, inplace=True)\n",
    "\n",
    "    # standardize the features\n",
    "    cols_ = list(sub_dataset.columns)[1:]\n",
    "    if not ecfp :\n",
    "        sub_dataset[cols_] = sub_dataset[cols_].apply(standardize, axis=0)\n",
    "\n",
    "    # for split in range(1, splits+1):\n",
    "    pool = multiprocessing.Pool(num_pools)\n",
    "    res = pool.starmap(best_model_runing, zip(range(1, repetitions + 1)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for item in res:\n",
    "        for i in range(3):\n",
    "            pd_res.append(item[i])\n",
    "if task_type == 'cla':\n",
    "    stat_res = pd.DataFrame(pd_res, columns=['split', 'dataset', 'subtask', 'set',\n",
    "                                             'num_of_retained_feature',\n",
    "                                             'num_of_compounds', 'postives',\n",
    "                                             'negtives', 'negtives/postives',\n",
    "                                             'tn', 'fp', 'fn', 'tp', 'se', 'sp',\n",
    "                                             'auc_prc', 'acc', 'auc_roc','recall','precision','f1','kappa','mcc'])\n",
    "else:\n",
    "    stat_res = pd.DataFrame(pd_res, columns=['split', 'dataset', 'subtask', 'set',\n",
    "                                             'num_of_retained_feature',\n",
    "                                             'num_of_compounds', 'rmse', 'r2', 'mae'])\n",
    "stat_res.to_csv('./model/' + dataset_label + '_EXT_statistical_results_split.csv', index=0)\n",
    "# single tasks\n",
    "if len(tasks) == 1:\n",
    "    args = {'data_label': dataset_label, 'metric': 'auc_roc' if task_type == 'cla' else 'rmse', 'model': 'EXT'}\n",
    "    print('{}_{}: the mean {} for the training set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(\n",
    "            stat_res[stat_res['set'] == 'tr'][args['metric']]), np.std(\n",
    "            stat_res[stat_res['set'] == 'tr'][args['metric']])))\n",
    "    print(\n",
    "        '{}_{}: the mean {} for the validation set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(\n",
    "                stat_res[stat_res['set'] == 'va'][args['metric']]), np.std(\n",
    "                stat_res[stat_res['set'] == 'va'][args['metric']])))\n",
    "    print('{}_{}: the mean {} for the test set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                 args['metric'], np.mean(\n",
    "            stat_res[stat_res['set'] == 'te'][args['metric']]), np.std(\n",
    "            stat_res[stat_res['set'] == 'te'][args['metric']])))\n",
    "# multi-tasks\n",
    "else:\n",
    "    args = {'data_label': dataset_label, 'metric': 'auc_roc' if dataset_label != 'muv' else 'auc_prc', 'model': 'EXT'}\n",
    "    tr_acc = np.zeros(repetitions)\n",
    "    va_acc = np.zeros(repetitions)\n",
    "    te_acc = np.zeros(repetitions)\n",
    "    for subtask in tasks:\n",
    "        tr = stat_res[stat_res['set'] == 'tr']\n",
    "        tr_acc = tr_acc + tr[tr['subtask'] == subtask][args['metric']].values\n",
    "\n",
    "        va = stat_res[stat_res['set'] == 'va']\n",
    "        va_acc = va_acc + va[va['subtask'] == subtask][args['metric']].values\n",
    "\n",
    "        te = stat_res[stat_res['set'] == 'te']\n",
    "        te_acc = te_acc + te[te['subtask'] == subtask][args['metric']].values\n",
    "    tr_acc = tr_acc / len(tasks)\n",
    "    va_acc = va_acc / len(tasks)\n",
    "    te_acc = te_acc / len(tasks)\n",
    "    print('{}_{}: the mean {} for the training set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(tr_acc),\n",
    "                                                                                     np.std(tr_acc)))\n",
    "    print(\n",
    "        '{}_{}: the mean {} for the validation set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(va_acc),\n",
    "                                                                                     np.std(va_acc)))\n",
    "    print('{}_{}: the mean {} for the test set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                 args['metric'], np.mean(te_acc),\n",
    "                                                                                 np.std(te_acc)))\n",
    "end = time.time()  # get the end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50bc4eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the elapsed time is: 0.13917755908436247 H\n"
     ]
    }
   ],
   "source": [
    "# acc auc_roc recall precision f1 kappa mcc\n",
    "acc_str = 'acc of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['acc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['acc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['acc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['acc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['acc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['acc']),\n",
    ")\n",
    "auc_str = 'auc_roc of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['auc_roc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['auc_roc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['auc_roc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['auc_roc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['auc_roc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['auc_roc']),\n",
    ")\n",
    "recall_str = 'recall of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['recall']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['recall']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['recall']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['recall']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['recall']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['recall']),\n",
    ")\n",
    "precision_str = 'precision of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['precision']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['precision']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['precision']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['precision']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['precision']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['precision']),\n",
    ")\n",
    "f1_str = 'f1 of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['f1']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['f1']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['f1']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['f1']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['f1']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['f1']),\n",
    ")\n",
    "kappa_str = 'kappa of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['kappa']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['kappa']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['kappa']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['kappa']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['kappa']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['kappa']),\n",
    ")\n",
    "mcc_str = 'mcc of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['mcc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['mcc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['mcc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['mcc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['mcc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['mcc']),\n",
    ")\n",
    "print('the elapsed time is:', (end - start)/3600, 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfb4f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of training set is 0.878±0.003, validation set is 0.874±0.012, test set is 0.876±0.009\n",
      "auc_roc of training set is 0.898±0.002, validation set is 0.897±0.012, test set is 0.899±0.013\n",
      "recall of training set is 0.407±0.008, validation set is 0.392±0.036, test set is 0.404±0.021\n",
      "precision of training set is 0.891±0.007, validation set is 0.904±0.044, test set is 0.904±0.033\n",
      "f1 of training set is 0.558±0.007, validation set is 0.545±0.034, test set is 0.558±0.021\n",
      "kappa of training set is 0.499±0.008, validation set is 0.485±0.035, test set is 0.498±0.023\n",
      "mcc of training set is 0.550±0.006, validation set is 0.544±0.030, test set is 0.553±0.022\n"
     ]
    }
   ],
   "source": [
    "print(acc_str)\n",
    "print(auc_str)\n",
    "print(recall_str)\n",
    "print(precision_str)\n",
    "print(f1_str)\n",
    "print(kappa_str)\n",
    "print(mcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee4ebafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/output_ext.txt', 'w') as f:\n",
    "    f.write(acc_str+'\\n')\n",
    "    f.write(auc_str+'\\n')\n",
    "    f.write(recall_str+'\\n')\n",
    "    f.write(precision_str+'\\n')\n",
    "    f.write(f1_str+'\\n')\n",
    "    f.write(kappa_str+'\\n')\n",
    "    f.write(mcc_str+'\\n')\n",
    "    f.write(str(cols_)+'\\n')\n",
    "cols_ = pd.DataFrame(cols_)\n",
    "cols_.to_csv('output/output_ext_cols.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aaad1fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model: EXT</th>\n",
       "      <th>Train</th>\n",
       "      <th>Tr_STD</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Va_STD</th>\n",
       "      <th>Test</th>\n",
       "      <th>Te_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.877744</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.873818</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.009345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.898046</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.896649</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.899395</td>\n",
       "      <td>0.013498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.406663</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.391975</td>\n",
       "      <td>0.036121</td>\n",
       "      <td>0.403988</td>\n",
       "      <td>0.020508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.904477</td>\n",
       "      <td>0.043758</td>\n",
       "      <td>0.904466</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.558340</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.545474</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>0.558123</td>\n",
       "      <td>0.021362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kappa</td>\n",
       "      <td>0.498623</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.485459</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.497783</td>\n",
       "      <td>0.022537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.550485</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.543682</td>\n",
       "      <td>0.029516</td>\n",
       "      <td>0.552951</td>\n",
       "      <td>0.022302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>auc_prc</td>\n",
       "      <td>0.756877</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.752847</td>\n",
       "      <td>0.022725</td>\n",
       "      <td>0.758748</td>\n",
       "      <td>0.026440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model: EXT      Train    Tr_STD  Validation    Va_STD      Test    Te_STD\n",
       "0         acc  0.877744  0.002652    0.873818  0.012444  0.875614  0.009345\n",
       "1     auc_roc  0.898046  0.001930    0.896649  0.012217  0.899395  0.013498\n",
       "2      recall  0.406663  0.008362    0.391975  0.036121  0.403988  0.020508\n",
       "3   precision  0.890831  0.007442    0.904477  0.043758  0.904466  0.033151\n",
       "4          f1  0.558340  0.007493    0.545474  0.034084  0.558123  0.021362\n",
       "5       kappa  0.498623  0.008002    0.485459  0.034773  0.497783  0.022537\n",
       "6         mcc  0.550485  0.006367    0.543682  0.029516  0.552951  0.022302\n",
       "7     auc_prc  0.756877  0.003630    0.752847  0.022725  0.758748  0.026440"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "dict1 = {\"model: EXT \":['acc','auc_roc','recall','precision','f1','kappa','mcc','auc_prc'],\n",
    "         \"Train\":[np.mean(stat_res[stat_res['set'] == 'tr']['acc']),np.mean(stat_res[stat_res['set'] == 'tr']['auc_roc']),\n",
    "                  np.mean(stat_res[stat_res['set'] == 'tr']['recall']),np.mean(stat_res[stat_res['set'] == 'tr']['precision']),\n",
    "                  np.mean(stat_res[stat_res['set'] == 'tr']['f1']),np.mean(stat_res[stat_res['set'] == 'tr']['kappa']),\n",
    "                  np.mean(stat_res[stat_res['set'] == 'tr']['mcc']),np.mean(stat_res[stat_res['set'] == 'tr']['auc_prc']),                                     \n",
    "                 ],\n",
    "         \"Tr_STD\":[np.std(stat_res[stat_res['set'] == 'tr']['acc']),np.std(stat_res[stat_res['set'] == 'tr']['auc_roc']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'tr']['recall']),np.std(stat_res[stat_res['set'] == 'tr']['precision']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'tr']['f1']),np.std(stat_res[stat_res['set'] == 'tr']['kappa']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'tr']['mcc']),np.std(stat_res[stat_res['set'] == 'tr']['auc_prc']),],\n",
    "         \"Validation\":[np.mean(stat_res[stat_res['set'] == 'va']['acc']),np.mean(stat_res[stat_res['set'] == 'va']['auc_roc']),\n",
    "                      np.mean(stat_res[stat_res['set'] == 'va']['recall']),np.mean(stat_res[stat_res['set'] == 'va']['precision']),\n",
    "                      np.mean(stat_res[stat_res['set'] == 'va']['f1']),np.mean(stat_res[stat_res['set'] == 'va']['kappa']),\n",
    "                      np.mean(stat_res[stat_res['set'] == 'va']['mcc']),np.mean(stat_res[stat_res['set'] == 'va']['auc_prc'])],\n",
    "         \"Va_STD\":[np.std(stat_res[stat_res['set'] == 'va']['acc']),np.std(stat_res[stat_res['set'] == 'va']['auc_roc']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'va']['recall']),np.std(stat_res[stat_res['set'] == 'va']['precision']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'va']['f1']),np.std(stat_res[stat_res['set'] == 'va']['kappa']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'va']['mcc']),np.std(stat_res[stat_res['set'] == 'va']['auc_prc'])],\n",
    "         \"Test\":[np.mean(stat_res[stat_res['set'] == 'te']['acc']),np.mean(stat_res[stat_res['set'] == 'te']['auc_roc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['recall']),np.mean(stat_res[stat_res['set'] == 'te']['precision']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['f1']),np.mean(stat_res[stat_res['set'] == 'te']['kappa']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['mcc']),np.mean(stat_res[stat_res['set'] == 'te']['auc_prc'])],\n",
    "          \"Te_STD\":[np.std(stat_res[stat_res['set'] == 'te']['acc']),np.std(stat_res[stat_res['set'] == 'te']['auc_roc']),\n",
    "                   np.std(stat_res[stat_res['set'] == 'te']['recall']),np.std(stat_res[stat_res['set'] == 'te']['precision']),\n",
    "                   np.std(stat_res[stat_res['set'] == 'te']['f1']),np.std(stat_res[stat_res['set'] == 'te']['kappa']),\n",
    "                   np.std(stat_res[stat_res['set'] == 'te']['mcc']),np.std(stat_res[stat_res['set'] == 'te']['auc_prc']),]}\n",
    "dict1 = collections.OrderedDict(dict1)\n",
    "df = pd.DataFrame(dict1,index = None)\n",
    "df.to_csv('output/output_ext.csv',index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "117ac76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_split</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <td>0.895305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <td>0.0151813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criterion</th>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bootstrap</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Values\n",
       "n_estimators                 191\n",
       "max_depth                      4\n",
       "min_samples_split              4\n",
       "min_samples_leaf               3\n",
       "max_features            0.895305\n",
       "min_impurity_decrease  0.0151813\n",
       "criterion                entropy\n",
       "bootstrap                   True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option ( 'display.width', None)\n",
    "pd.set_option ( 'display.max_columns', None) #显示全部列\n",
    "hyper_parameters = best_hyper.iloc[0:1,8:-14].T\n",
    "hyper_parameters.rename(columns={0:'Values'},inplace=True) \n",
    "hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799111e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-dgl]",
   "language": "python",
   "name": "conda-env-anaconda3-dgl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
